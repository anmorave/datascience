{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anmorave/datascience/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf6OOaMzlJiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUay3sYBlfld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# =============================================================================\n",
        "# Definiciones y funciones\n",
        "# =============================================================================\n",
        "\n",
        "default_stopwords_es = nltk.corpus.stopwords.words('spanish')\n",
        "default_stopwords_pg = nltk.corpus.stopwords.words('portuguese')\n",
        "all_stopwords = list(set(default_stopwords_es)|set(default_stopwords_pg))\n",
        "\n",
        "def remove_shortW(words):\n",
        "    return [word for word in words if len(word) > 2]\n",
        "\n",
        "def remove_numc(words):\n",
        "    return [word for word in words if not (word[0].isnumeric() or word[-1].isnumeric())]\n",
        "\n",
        "def remove_noChar(words):\n",
        "    return [re.sub(u\"[^a-zA-ZñÑáéíóúÁÉÍÓÚ ]\",\"\", word) for word in words]\n",
        "\n",
        "def remove_shortW(words):\n",
        "    return [word for word in words if len(word) > 2]\n",
        "\n",
        "def remove_sw(words,sw_list):\n",
        "    return [word for word in words if word not in sw_list]\n",
        "\n",
        "def remove_sc(words):\n",
        "    return [re.sub(u'([^a-z|0-9|A-Z|ZñÑáéíóúÁÉÍÓÚ])',' ',word) for word in words]\n",
        "  \n",
        "def remove_sc_str(words):\n",
        "    return re.sub(u'([^a-z|0-9|A-Z|ZñÑáéíóúÁÉÍÓÚ])',' ',words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_kspmWkltX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a4deea3f-4a67-40f8-9500-7caca02afcf3"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_9SWnPClhT6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "38c2ac99-9a1e-41f9-9e30-a0c909538f39"
      },
      "source": [
        "# =============================================================================\n",
        "# Exploración\n",
        "# =============================================================================\n",
        "#Español y confiable\n",
        "inicio = time.time()\n",
        "train = pd.read_csv(r'/train.csv')\n",
        "\n",
        "categorias = pd.unique(train['category'])\n",
        "\n",
        "espa_y_confiable = (train['language']=='spanish') & (train['label_quality']=='reliable')\n",
        "\n",
        "es_re_cat = [train['title'][(train['category']==itera) & espa_y_confiable] for itera in categorias[1:100]]\n",
        "es_re_cat_clean = [remove_sc(titulo) for titulo in es_re_cat]\n",
        "es_re_cat_clean = [[nltk.word_tokenize(uno.lower()) for uno in titulo] for titulo in es_re_cat_clean]\n",
        "es_re_cat_clean = [[remove_numc(uno) for uno in titulo] for titulo in es_re_cat_clean]\n",
        "es_re_cat_clean = [[remove_shortW(uno) for uno in titulo] for titulo in es_re_cat_clean]\n",
        "es_re_cat_clean = [[remove_sw(uno,all_stopwords) for uno in titulo] for titulo in es_re_cat_clean]\n",
        "print(time.time()-inicio)\n",
        "\n",
        "\n",
        "flat_list = [[item for sublist in cat for item in sublist] for cat in es_re_cat_clean]\n",
        "es_re_cat_frecuencias = [pd.DataFrame(data=({'palabra':list(nltk.FreqDist(itera).keys()),'frecuencia':list(nltk.FreqDist(itera).values())})).sort_values(by=['frecuencia'],ascending=False) for itera in flat_list]\n",
        "conteo = [[(set(coso) and set(es_re_cat_frecuencias[0]['palabra'][0:4])) == set(es_re_cat_frecuencias[0]['palabra'][0:4]) for coso in cat] for cat in es_re_cat_clean]\n",
        "teoria = [sum(a)/(len(a)+0.00000000000000000001) for a in conteo]\n",
        "\n",
        "palabras_cat = [list(cosa['palabra'][0:4]) for cosa in es_re_cat_frecuencias]\n",
        "palabras_cat_uno = [item for sublist in palabras_cat for item in sublist]\n",
        "\n",
        "#flat_list = [[item for sublist in es_re_cat_clean[0] for item in sublist]\n",
        "#es_re_cat_frecuencias = pd.DataFrame(data=({'palabra':list(nltk.FreqDist(flat_list).keys()),'frecuencia':list(nltk.FreqDist(flat_list).values())}))\n",
        "#conteo = [set(coso) and set(list(es_re_cat_frecuencias[es_re_cat_frecuencias['frecuencia']>113]['palabra']))==set(list(es_re_cat_frecuencias[es_re_cat_frecuencias['frecuencia']>113]['palabra'])) for coso in es_re_cat_clean[0]]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.7259175777435303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-CkaDC8mh5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e35bfee2-7158-4344-8a91-ba083acdef5e"
      },
      "source": [
        "inicio = time.time()\n",
        "titles_category = [train['title'][(train['category']==itera)] for itera in categorias]\n",
        "titles_category_clean = [remove_sc(titulo) for titulo in titles_category]\n",
        "titles_category_clean = [[nltk.word_tokenize(uno.lower()) for uno in titulo] for titulo in titles_category_clean]\n",
        "titles_category_clean = [[remove_numc(uno) for uno in titulo] for titulo in titles_category_clean]\n",
        "titles_category_clean = [[remove_shortW(uno) for uno in titulo] for titulo in titles_category_clean]\n",
        "titles_category_clean = [[remove_sw(uno,all_stopwords) for uno in titulo] for titulo in titles_category_clean]\n",
        "\n",
        "flat_list = [[item for sublist in cat for item in sublist] for cat in titles_category_clean]\n",
        "frecuencias = [pd.DataFrame(data=({'palabra':list(nltk.FreqDist(itera).keys()),'frecuencia':list(nltk.FreqDist(itera).values())})).sort_values(by=['frecuencia'],ascending=False) for itera in flat_list]\n",
        "conteo = [[(set(coso) & set(frecuencias[0]['palabra'][0:4])) == set(frecuencias[0]['palabra'][0:4]) for coso in cat] for cat in titles_category_clean]\n",
        "teoria = [sum(a)/(len(a)+0.00000000000000000001) for a in conteo]\n",
        "print(time.time()-inicio)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "215.93643522262573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cb8pbPZncxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "93fb1c83-5b7e-453f-d969-d552e3b2772f"
      },
      "source": [
        "\n",
        "palabras = [list(cosa['palabra'][0:4]) for cosa in frecuencias]\n",
        "palabras_uno = [item for sublist in palabras for item in sublist]\n",
        "len(palabras_uno)-len(pd.unique(palabras_uno))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3028"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOogXbcDpTVb",
        "colab_type": "text"
      },
      "source": [
        "Predicciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY__qshQpjpd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0a9130f7-dd17-4ca6-e872-3d9169ad2ac6"
      },
      "source": [
        "regla = [set(coso['palabra'][0:4]) for coso in frecuencias]\n",
        "regla[0]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alta', 'hidrolavadora', 'lavadora', 'press'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ammmWNI0o2fM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv(r'/test.csv')\n",
        "test_titles = list(test['title'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ZB18vQuTJZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e022e63-7c07-4598-8277-1365b0d02b7d"
      },
      "source": [
        "inicio = time.time()\n",
        "test_titles_clean = [remove_sc_str(uno) for uno  in test_titles]\n",
        "test_titles_clean = [nltk.word_tokenize(uno.lower()) for uno in test_titles_clean]\n",
        "test_titles_clean = [remove_numc(uno) for uno in test_titles_clean]\n",
        "test_titles_clean = [remove_shortW(uno) for uno in test_titles_clean]\n",
        "test_titles_clean = [remove_sw(uno,all_stopwords) for uno in test_titles_clean]\n",
        "test_titles_clean\n",
        "print(time.time()-inicio)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37.050885915756226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMCFo9n8v6P2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conteo = [[(set(coso) and set(frecuencias[0]['palabra'][0:4])) == set(frecuencias[0]['palabra'][0:4]) for coso in cat] for cat in test_titles_clean]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL1EvXJVuFeU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "bb88b2d2-6d71-4ddf-cee6-b32844cd78de"
      },
      "source": [
        "set(test_titles_clean[0]) & ()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bolsa', 'mala', 'maternidade', 'vinho', 'menina', 'bebe', 'kit', 'baby'}\n",
            "{'alta', 'lavadora', 'hidrolavadora', 'press'}\n",
            "{'alta', 'lavadora', 'hidrolavadora', 'press'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h2MSXwyzTMG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "f91112cd-b2b3-432a-cbfc-54b945672d74"
      },
      "source": [
        "set([1,2,3]).issubset()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-ffb49ebeb182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: set expected at most 1 arguments, got 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feGqatktzwoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "69b3fc7c-c91d-477d-84fb-f40a9d045fbc"
      },
      "source": [
        "t=[[1,2,3],[4,5,2]]\n",
        "t1 = set(frozenset(i) for i in t)\n",
        "set([1,2,3]).issubset(t1)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    }
  ]
}